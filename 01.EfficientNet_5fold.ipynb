{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.EfficientNet_5fold.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNQC6XiEE35oR2HHxDnzQin"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Initial Settings"],"metadata":{"id":"K80jR3O6rW41"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"shiwPf31od3V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652709535345,"user_tz":-540,"elapsed":104101,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"f7dddae5-9a0a-48c5-f0b0-ce9deaca909c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n","Collecting https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n","  Using cached https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.11.0+cu113)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (0.12.0+cu113)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.3.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler==0.1.1) (4.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler==0.1.1) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (3.0.4)\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive/')\n","path='/content/gdrive/My Drive/Colab Notebooks/06_Anomaly/'\n","\n","import os\n","os.chdir(path)\n","\n","!pip install timm\n","!pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip"]},{"cell_type":"markdown","source":["#Library"],"metadata":{"id":"Jp7lii4mrVZd"}},{"cell_type":"code","source":["import torch.optim as optim\n","import albumentations as A\n","import torch.nn as nn\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np \n","import random\n","import torch\n","import timm\n","import cv2\n","import os\n","import time\n","import sys\n","\n","from torchsampler.imbalanced import ImbalancedDatasetSampler\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset, DataLoader\n","from albumentations.pytorch import ToTensor\n","from glob import glob\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","\n","device = torch.device('cuda')"],"metadata":{"id":"6u773cUhrkUu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습을 위한 Hyperparameter 셋팅"],"metadata":{"id":"kxzmouMYrxzs"}},{"cell_type":"code","source":["seed = 51\n","random.seed(seed)\n","torch.manual_seed(seed)\n","\n","lr = 1e-3\n","folds = 5\n","batch_size = 16\n","epochs = 70\n","\n","resized_image = 512\n","crop_image = 498"],"metadata":{"id":"gVSur-Ihr64a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# image augmentation"],"metadata":{"id":"ftLnJf5QsI6P"}},{"cell_type":"code","source":["albumentations_transform = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","albumentations_transform_pred = A.Compose([\n","    ToTensor()\n","])"],"metadata":{"id":"mIwa8Q4wsOve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Custom Dataset & Model"],"metadata":{"id":"OnCoTNQ_sUfg"}},{"cell_type":"code","source":["class Custom_dataset(Dataset):\n","    def __init__(self, img_paths, labels, mode='train',transform = None):\n","        self.img_paths = img_paths\n","        self.labels = labels\n","        self.mode = mode\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = self.img_paths[idx]\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","\n","        label = self.labels[idx]\n","        return img, label\n","\n","    def get_labels(self):\n","        return self.labels\n","\n","class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)\n","        \n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"YzhLdG7tsaYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def img_load(path):\n","    img = cv2.imread(path)[:,:,::-1]\n","    img = cv2.resize(img, (resized_image, resized_image))\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    return img"],"metadata":{"id":"aMdMs3ggtJhE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_png = sorted(glob('open/train/*.png'))\n","\n","train_y = pd.read_csv(\"open/train_df.csv\")\n","train_labels = train_y[\"label\"]\n","\n","label_unique = sorted(np.unique(train_labels))\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","train_labels = [label_unique[k] for k in train_labels]\n","train_imgs = [img_load(m) for m in tqdm(train_png)]\n","\n","train_dataset = Custom_dataset(train_imgs, train_labels, mode='train',transform=albumentations_transform)"],"metadata":{"id":"vWiinxsftCcj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652709722136,"user_tz":-540,"elapsed":184733,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"b1c4db1f-9c05-43fa-8158-12991c65bede"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4277/4277 [03:05<00:00, 23.10it/s]\n"]}]},{"cell_type":"markdown","source":["# f1 Score function\n"],"metadata":{"id":"jVQfsGintXjr"}},{"cell_type":"code","source":["def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\")\n","    return score"],"metadata":{"id":"MQdoXhnItWU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train (5 fold)"],"metadata":{"id":"NED0m7ows7u_"}},{"cell_type":"code","source":["kfold = StratifiedKFold(n_splits=folds,shuffle=True,random_state = seed)\n","\n","k_loss_plot, k_val_loss_plot = [],[]\n","for fold, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset,train_labels)):\n","  sub_train_imgs = [train_imgs[i] for i in train_idx]\n","  sub_train_labs = [train_labels[i] for i in train_idx]\n","  sub_train_dataset = Custom_dataset(sub_train_imgs,sub_train_labs, mode='train',transform = albumentations_transform )\n","\n","  sub_valid_imgs = [train_imgs[i] for i in valid_idx]\n","  sub_valid_labs = [train_labels[i] for i in valid_idx]\n","  valid_dataset = Custom_dataset(sub_valid_imgs, sub_valid_labs, mode='test',transform =albumentations_transform_pred )\n","\n","  train_subsampler = ImbalancedDatasetSampler(sub_train_dataset)\n","\n","  train_loader = DataLoader(sub_train_dataset, batch_size=batch_size,sampler = train_subsampler)\n","  valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n","\n","  model = Network().to(device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","  criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","  scaler = torch.cuda.amp.GradScaler() \n","\n","  val_loss_plot, val_score_plot = [], []\n","  best=0\n","  for epoch in range(epochs):\n","      start=time.time()\n","      train_loss = 0\n","      train_pred=[]\n","      train_y=[]\n","      model.train()\n","      for batch in (train_loader):\n","          optimizer.zero_grad()\n","          x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n","          y = torch.tensor(batch[1], dtype=torch.long, device=device)\n","          with torch.cuda.amp.autocast():\n","              pred = model(x)\n","          loss = criterion(pred, y)\n","\n","          scaler.scale(loss).backward()\n","          scaler.step(optimizer)\n","          scaler.update()\n","          \n","          train_loss += loss.item()/len(train_loader)\n","          train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","          train_y += y.detach().cpu().numpy().tolist()\n","          \n","      # scheduler.step()\n","\n","      train_f1 = score_function(train_y, train_pred)\n","\n","      TIME = time.time() - start\n","      print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n","      print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n","\n","      #valid\n","      valid_loss = 0\n","      valid_pred=[]\n","      valid_y=[]\n","      model.eval()\n","      for batch in (valid_loader):\n","          optimizer.zero_grad()\n","          x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n","          y = torch.tensor(batch[1], dtype=torch.long, device=device)\n","          with torch.no_grad():\n","              pred = model(x)\n","          loss = criterion(pred, y)\n","          \n","          valid_loss += loss.item()/len(train_loader)\n","          valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","          valid_y += y.detach().cpu().numpy().tolist()\n","          \n","      \n","      valid_f1 = score_function(valid_y, valid_pred)\n","\n","      TIME = time.time() - start\n","      print(f'Valid    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}')\n","      val_score_plot.append(valid_f1)\n","      val_loss_plot.append(valid_loss)\n","      ##save model\n","      if np.max(val_score_plot) == val_score_plot[-1]:\n","        torch.save(model.state_dict(), \"./model/\"+str(fold)+\".pt\")"],"metadata":{"id":"SGiKjwgJtjBk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc3a59b7-f1d2-4eff-ae6e-aba06576d585"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 1/70    time : 143s/9878s\n","TRAIN    loss : 2.19655    f1 : 0.48315\n","Valid    loss : 0.33271    f1 : 0.60425\n"]}]}]}