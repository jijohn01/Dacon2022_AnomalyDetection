{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03.Augmentation_by_class.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNIbuSDqHe/JImbABLfgrVm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Initial Settings"],"metadata":{"id":"K80jR3O6rW41"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"shiwPf31od3V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652711732215,"user_tz":-540,"elapsed":9834,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"52a266d8-d9c7-4eb0-d33f-762005d31d7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n","Collecting https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n","  Using cached https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.11.0+cu113)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (0.12.0+cu113)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.3.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler==0.1.1) (4.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler==0.1.1) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler==0.1.1) (3.0.4)\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive/')\n","path='/content/gdrive/My Drive/Colab Notebooks/06_Anomaly/'\n","\n","import os\n","os.chdir(path)\n","\n","!pip install timm\n","!pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip"]},{"cell_type":"markdown","source":["#Library"],"metadata":{"id":"Jp7lii4mrVZd"}},{"cell_type":"code","source":["import torch.optim as optim\n","import albumentations as A\n","import torch.nn as nn\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np \n","import random\n","import torch\n","import timm\n","import cv2\n","import os\n","import time\n","import sys\n","\n","from torchsampler.imbalanced import ImbalancedDatasetSampler\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset, DataLoader\n","from albumentations.pytorch import ToTensor\n","from glob import glob\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","\n","device = torch.device('cuda')"],"metadata":{"id":"6u773cUhrkUu","executionInfo":{"status":"ok","timestamp":1652711734260,"user_tz":-540,"elapsed":2048,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# 학습을 위한 Hyperparameter 셋팅"],"metadata":{"id":"kxzmouMYrxzs"}},{"cell_type":"code","source":["seed = 51\n","random.seed(seed)\n","torch.manual_seed(seed)\n","\n","lr = 1e-3\n","folds = 5\n","batch_size = 16\n","epochs = 250\n","\n","resized_image = 700\n","crop_image = 670"],"metadata":{"id":"gVSur-Ihr64a","executionInfo":{"status":"ok","timestamp":1652711734261,"user_tz":-540,"elapsed":6,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# image augmentation"],"metadata":{"id":"ftLnJf5QsI6P"}},{"cell_type":"code","source":["transform_bottle = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_cable = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.RandomRotate90(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_capsule = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_carpet = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_grid = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_hazelnut = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_leather = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_metal_nut = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.RandomRotate90(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_pill = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_screw = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_tile = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_toothbrush = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_transistor = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_wood = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=40, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","transform_zipper = A.Compose([\n","    A.RandomCrop(crop_image, crop_image),\n","    A.HorizontalFlip(p=0.5), # Same with transforms.RandomHorizontalFlip()\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(),\n","    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=1, p=0.5),\n","    A.GridDistortion(always_apply=False, p=0.5, num_steps=10, distort_limit=(-0.2, 0.2), interpolation=2, border_mode=0),\n","    A.Cutout(always_apply=False, p=0.5, num_holes=50, max_h_size=10, max_w_size=10),\n","    ToTensor()\n","])\n","\n","transforms = {\"bottle\": transform_bottle,\n","              \"cable\":transform_cable,\n","              \"capsule\":transform_capsule,\n","              \"carpet\":transform_carpet,\n","              \"grid\": transform_grid,\n","              \"hazelnut\":transform_hazelnut,\n","              \"leather\":transform_leather,\n","              \"metal_nut\":transform_metal_nut,\n","              \"pill\":transform_pill,\n","              \"screw\":transform_screw,\n","              \"tile\":transform_tile,\n","              \"toothbrush\": transform_toothbrush,\n","              \"transistor\":transform_transistor,\n","              \"wood\":transform_wood,\n","              \"zipper\":transform_zipper}\n","\n","transform_pred = A.Compose([\n","    ToTensor()\n","])"],"metadata":{"id":"mIwa8Q4wsOve","executionInfo":{"status":"ok","timestamp":1652711734261,"user_tz":-540,"elapsed":5,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#Custom Dataset & Model"],"metadata":{"id":"OnCoTNQ_sUfg"}},{"cell_type":"code","source":["class Custom_dataset(Dataset):\n","    def __init__(self, img_arr_list, labels, classes = None, mode='train', transforms=None):\n","        self.img_arr_list = img_arr_list\n","        self.labels = labels\n","        self.classes = classes\n","        self.labels_arr = np.array(labels)\n","        self.mode = mode\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.img_arr_list)\n","\n","    def __getitem__(self, idx):\n","        img = self.img_arr_list[idx]\n","        \n","        if self.mode == 'train':\n","            clas = self.classes[idx]\n","            img = self.transforms[clas](image=img)['image']\n","\n","        elif self.mode == 'test':\n","            img = self.transforms(image=img)['image']\n","\n","        label = self.labels[idx]\n","\n","        return img, label\n","\n","    def get_labels(self):\n","        return self.labels\n","\n","class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)\n","        \n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"YzhLdG7tsaYi","executionInfo":{"status":"ok","timestamp":1652711734261,"user_tz":-540,"elapsed":5,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def img_load(path):\n","    img = cv2.imread(path)[:,:,::-1]\n","    img = cv2.resize(img, (resized_image, resized_image))\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    return img"],"metadata":{"id":"aMdMs3ggtJhE","executionInfo":{"status":"ok","timestamp":1652711734262,"user_tz":-540,"elapsed":6,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_png = sorted(glob('train/*.png'))\n","\n","train_y = pd.read_csv(\"open/train_df.csv\")\n","train_labels_str = train_y[\"label\"]\n","train_classes = train_y[\"class\"]\n","\n","label_unique = sorted(np.unique(train_labels_str))\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","train_labels = [label_unique[k] for k in train_labels_str]\n","train_imgs = [img_load(m) for m in tqdm(train_png)]\n","\n","train_dataset = Custom_dataset(train_imgs, train_labels,classes=train_classes, mode='train',transforms=transforms)"],"metadata":{"id":"vWiinxsftCcj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652711880656,"user_tz":-540,"elapsed":146400,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"61a37c43-a77d-4ffc-8e10-29ad937db845"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4277/4277 [02:26<00:00, 29.25it/s]\n"]}]},{"cell_type":"markdown","source":["# f1 Score function\n"],"metadata":{"id":"jVQfsGintXjr"}},{"cell_type":"code","source":["def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\")\n","    return score"],"metadata":{"id":"MQdoXhnItWU5","executionInfo":{"status":"ok","timestamp":1652711880657,"user_tz":-540,"elapsed":5,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, classes, smoothing=0.0, dim=-1, weight = None):\n","        \"\"\"if smoothing == 0, it's one-hot method\n","           if 0 < smoothing < 1, it's smooth method\n","        \"\"\"\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.weight = weight\n","        self.cls = classes\n","        self.dim = dim\n","\n","    def forward(self, pred, target):\n","        assert 0 <= self.smoothing < 1\n","        pred = pred.log_softmax(dim=self.dim)\n","\n","        if self.weight is not None:\n","            pred = pred * self.weight.unsqueeze(0)   \n","\n","        with torch.no_grad():\n","            true_dist = torch.zeros_like(pred)\n","            true_dist.fill_(self.smoothing / (self.cls - 1))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"],"metadata":{"id":"4sFAU8A6Sx0E","executionInfo":{"status":"ok","timestamp":1652711880657,"user_tz":-540,"elapsed":4,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Train\n","* Augmentation을 class에 따라 다르게 적용하였으나 눈에 띄는 성능향상은 없었음\n","* 실험이 부족"],"metadata":{"id":"NED0m7ows7u_"}},{"cell_type":"code","source":["kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n","\n","for fold, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset, train_labels)):\n","    sub_train_imgs = [train_imgs[i] for i in train_idx]\n","    sub_train_labs = [train_labels[i] for i in train_idx]\n","    sub_train_clas = [train_classes[i] for i in train_idx]\n","    sub_train_dataset = Custom_dataset(sub_train_imgs, sub_train_labs, classes= sub_train_clas, mode='train', transforms=transforms)\n","\n","    sub_valid_imgs = [train_imgs[i] for i in valid_idx]\n","    sub_valid_labs = [train_labels[i] for i in valid_idx]\n","    sub_valid_class = [train_classes[i] for i in valid_idx]\n","    valid_dataset = Custom_dataset(sub_valid_imgs, sub_valid_labs,classes = sub_valid_class, mode='test',transforms=transform_pred)\n","\n","    train_subsampler = ImbalancedDatasetSampler(sub_train_dataset)\n","    train_loader = DataLoader(sub_train_dataset, batch_size=batch_size, sampler = train_subsampler)\n","    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n","\n","    model = Network().to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,60], gamma=0.5)\n","    \n","    # class weight \n","    total_lbls = list(set(sub_train_labs))\n","    lbl_cnt = [sub_train_labs.count(label) for label in total_lbls]\n","    norm_weights = [1 - (cnt / sum(lbl_cnt)) for cnt in lbl_cnt]\n","    norm_weights = torch.FloatTensor(norm_weights).cuda()\n","    criterion = LabelSmoothingLoss(classes=88, smoothing=0.1, weight=norm_weights)\n","\n","    scaler = torch.cuda.amp.GradScaler() \n","\n","    val_loss_plot, val_score_plot = [], []\n","    global_step = 0\n","    for epoch in range(epochs):\n","        start=time.time()\n","        train_loss = 0\n","        train_pred=[]\n","        train_y=[]\n","        model.train()\n","        for step, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            x = torch.tensor(batch[0], dtype=torch.float32).cuda()\n","            y = torch.tensor(batch[1], dtype=torch.long).cuda()\n","\n","            with torch.cuda.amp.autocast():\n","                pred = model(x)\n","            loss = criterion(pred, y)\n","    \n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            train_loss += loss.item()/len(train_loader)\n","            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","            train_y += y.detach().cpu().numpy().tolist()\n","\n","            global_step += 1\n","        scheduler.step()\n","\n","        TIME = time.time() - start\n","        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n","\n","        # Validation\n","        valid_loss = 0\n","        valid_pred=[]\n","        valid_y=[]\n","        model.eval()\n","\n","        for batch in (valid_loader):\n","            optimizer.zero_grad()\n","            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n","            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n","            with torch.no_grad():\n","                pred = model(x)\n","            loss = criterion(pred, y)\n","\n","            valid_loss += loss.item()/len(train_loader)\n","            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","            valid_y += y.detach().cpu().numpy().tolist()\n","\n","        valid_f1 = score_function(valid_y, valid_pred)\n","\n","        TIME = time.time() - start\n","        print(f'Valid    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}')\n","        print(f'time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n","        val_score_plot.append(valid_f1)\n","        val_loss_plot.append(valid_loss)\n","\n","        ##save model\n","        if np.max(val_score_plot) == val_score_plot[-1]:\n","            torch.save(model.state_dict(), \".model3/\"+str(fold)+\".pt\")"],"metadata":{"id":"SGiKjwgJtjBk","colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"status":"error","timestamp":1652711886320,"user_tz":-540,"elapsed":5667,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"ccdeeb0d-5210-4249-a9ce-aee62745dc92"},"execution_count":10,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7c974164402a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-1807183c2fed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Depth-wise convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 14.76 GiB total capacity; 13.24 GiB already allocated; 21.75 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]}]}